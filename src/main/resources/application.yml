server:
  tomcat:
    uri-encoding: UTF-8
  port : 8883
  servlet:
      context-path: /ripple
spring:
  servlet:
      multipart:
        enabled: true
        max-file-size: 100MB
        max-request-size: 100MB
  application:
      name: ripple
  kafka:
          bootstrap-servers: 192.168.111.130:9092
          consumer:
              group-id: 0
              key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
              value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
          producer:
              key-serializer: org.apache.kafka.common.serialization.StringSerializer
              value-deserializer: org.apache.kafka.common.serialization.StringSerializer
              batch-size: 65536
              buffer-memory: 524288

#单体注掉
#spring-cloud
  cloud:
      client:
         ipAddress: localhost
  redis:
      host: 192.168.111.130
      port: 6379
      password: akRedis@123
      database: 1
  http:
    encoding:
      charset: UTF-8
      enabled: true
      force: true
  messages:
    encoding: UTF-8
  datasource:
    #JDBC基本配置
    url: jdbc:mysql://192.168.111.130:3306/ripple?useUnicode=true&characterEncoding=utf8&useSSL=false
    username: akdb
    password: AKdb@123
    #在springBoot2.1中数据库驱动类是不用手动指定的
    #driver-class-name: top.mysql.jdbc.Driver
    #连接池配置
    type: com.alibaba.druid.pool.DruidDataSource
    #监控访问地址 http://localhost:7878/ripple/druid/login.html
    druid:
      # 下面为连接池的补充设置，应用到上面所有数据源中
      # 初始化大小，最小，最大
      initial-size: 5
      min-idle: 5
      max-active: 20
      # 配置获取连接等待超时的时间
      max-wait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      time-between-eviction-runs-millis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      min-evictable-idle-time-millis: 300000
      validation-query: SELECT 1 FROM DUAL
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      # 打开PSCache，并且指定每个连接上PSCache的大小
      pool-prepared-statements: true
      #   配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
      max-pool-prepared-statement-per-connection-size: 20
      filters: stat,wall
      use-global-data-source-stat: true
      # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
      connect-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
      # 配置监控服务器
      stat-view-servlet:
        login-username: ak
        login-password: ak@123
        reset-enable: false
        url-pattern: /druid/*
        # 添加IP白名单
        #allow:
        # 添加IP黑名单，当白名单和黑名单重复时，黑名单优先级更高
        #deny:
      web-stat-filter:
        # 添加过滤规则
        url-pattern: /*
        # 忽略过滤格式
        exclusions: "*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*"

#单体注掉
#spring-cloud
eureka:
  client:
    #eureka client刷新本地缓存时间，默认30
    registry-fetch-interval-seconds: 5
    registerwitheureka: true
    serviceUrl :
      defaultZone: http://localhost:8881/eureka/
  instance:
    instance-id: ${spring.cloud.client.ipAddress}:${server.port}
    #Eureka客户端向服务端发送心跳的时间间隔，单位为秒（客户端告诉服务端自己会按照该规则），默认30
    lease-expiration-duration-in-seconds: 5
    #Eureka服务端在收到最后一次心跳之后等待的时间上限，单位为秒，超过则剔除（客户端告诉服务端按照此规则等待自己），默认90
    lease-renewal-interval-in-seconds: 7
    appname: ${spring.application.name}
    prefer-ip-address: true

#mybatis.typeAliasesPackage=top.coderakak.entity
#mybatis.mapperLocations=classpath\:mapper/*.xml

mybatis-plus:
  mapper-locations: classpath*:mybatis/mapper/*.xml
  config-locations: classpath*:mybatis/config.xml
  type-aliases-package: top.coderak.entity
  #自定义填充策略接口实现
  global-config.meta-object-handler: top.coderak.core.base.config.MyMetaObjectHandler
  
# 打印sql
logging:
  config: classpath:log/log4j2.xml
  level:
     top.coderak.mapper : debug
     top.coderak.core.base.mapper : debug



